{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":113002,"databundleVersionId":13471427,"sourceType":"competition"}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#pip install torch torchvision numpy pandas opencv-python scikit-learn","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2025-10-20T04:38:04.851272Z","iopub.execute_input":"2025-10-20T04:38:04.851660Z","iopub.status.idle":"2025-10-20T04:38:04.855413Z","shell.execute_reply.started":"2025-10-20T04:38:04.851628Z","shell.execute_reply":"2025-10-20T04:38:04.854645Z"},"trusted":true},"outputs":[],"execution_count":18},{"cell_type":"code","source":"import os\nimport cv2\nimport math\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport time as t\nfrom PIL import Image\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.models as models\nfrom torchvision import transforms\n\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2025-10-20T04:38:04.856676Z","iopub.execute_input":"2025-10-20T04:38:04.856893Z","iopub.status.idle":"2025-10-20T04:38:04.872095Z","shell.execute_reply.started":"2025-10-20T04:38:04.856877Z","shell.execute_reply":"2025-10-20T04:38:04.871357Z"},"trusted":true},"outputs":[],"execution_count":19},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-20T04:38:04.873039Z","iopub.execute_input":"2025-10-20T04:38:04.873246Z","iopub.status.idle":"2025-10-20T04:38:04.885943Z","shell.execute_reply.started":"2025-10-20T04:38:04.873231Z","shell.execute_reply":"2025-10-20T04:38:04.885184Z"}},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":"### Setting and parameters","metadata":{}},{"cell_type":"code","source":"IMG_SIZE = (224, 224)\nBATCH_SIZE = 32\nNUM_CLASSES = 14\nNUM_EPOCHS = 20\nLR = 1e-5\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nIMAGE_DIR_TRAIN = '/kaggle/input/grand-xray-slam-division-b/train2/'","metadata":{"execution":{"iopub.status.busy":"2025-10-20T04:38:04.887619Z","iopub.execute_input":"2025-10-20T04:38:04.887998Z","iopub.status.idle":"2025-10-20T04:38:04.897833Z","shell.execute_reply.started":"2025-10-20T04:38:04.887983Z","shell.execute_reply":"2025-10-20T04:38:04.897263Z"},"trusted":true},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":"### Load train data","metadata":{}},{"cell_type":"code","source":"try:\n    train_df = pd.read_csv('/kaggle/input/grand-xray-slam-division-b/train2.csv')\n    print(f\"Loaded train2.csv with {len(train_df)} rows\")\nexcept FileNotFoundError:\n    print(\"Error: train2.csv not found. Ensure dataset is attached.\")\n    raise\n\nlabel_columns = [\n    'Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Enlarged Cardiomediastinum',\n    'Fracture', 'Lung Lesion', 'Lung Opacity', 'No Finding', 'Pleural Effusion',\n    'Pleural Other', 'Pneumonia', 'Pneumothorax', 'Support Devices'\n]\n\nmissing_cols = [col for col in label_columns if col not in train_df.columns]\nif missing_cols:\n    raise KeyError(f\"Missing columns: {missing_cols}\")\n\nsubset_frac = 0.06\ndf_small = train_df.sample(frac=subset_frac, random_state=42)\n\n# split into train and validation (80/20)\ntrain_data, val_data = train_test_split(\n    df_small, test_size=0.2, random_state=42\n)\nprint(f\"Train samples: {len(train_data)}, Validation samples: {len(val_data)}\")","metadata":{"execution":{"iopub.status.busy":"2025-10-20T04:38:04.898519Z","iopub.execute_input":"2025-10-20T04:38:04.898772Z","iopub.status.idle":"2025-10-20T04:38:05.123540Z","shell.execute_reply.started":"2025-10-20T04:38:04.898758Z","shell.execute_reply":"2025-10-20T04:38:05.122730Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Loaded train2.csv with 108494 rows\nTrain samples: 5208, Validation samples: 1302\n","output_type":"stream"}],"execution_count":22},{"cell_type":"markdown","source":"### Augmentations","metadata":{}},{"cell_type":"code","source":"import albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\ntrain_transform = A.Compose([\n    A.LongestMaxSize(max_size=IMG_SIZE[0]),   \n    A.PadIfNeeded(min_height=IMG_SIZE[0], min_width=IMG_SIZE[1], border_mode=0),  \n    \n    A.HorizontalFlip(p=0.5),\n    A.ShiftScaleRotate(\n        shift_limit=0.02, scale_limit=0.05, rotate_limit=5, \n        border_mode=0, p=0.3\n    ),\n    A.RandomBrightnessContrast(\n        brightness_limit=0.05, contrast_limit=0.05, p=0.3\n    ),\n    A.CLAHE(clip_limit=2.0, tile_grid_size=(8,8), p=0.2),\n    \n    A.Normalize(mean=(0.5,), std=(0.5,)),  \n    ToTensorV2()\n])\n\nval_transform = A.Compose([\n    A.LongestMaxSize(max_size=IMG_SIZE[0]),\n    A.PadIfNeeded(min_height=IMG_SIZE[0], min_width=IMG_SIZE[1], border_mode=0),\n    A.Normalize(mean=(0.5,), std=(0.5,)),\n    ToTensorV2()\n])","metadata":{"execution":{"iopub.status.busy":"2025-10-20T04:38:05.124315Z","iopub.execute_input":"2025-10-20T04:38:05.124577Z","iopub.status.idle":"2025-10-20T04:38:05.136012Z","shell.execute_reply.started":"2025-10-20T04:38:05.124555Z","shell.execute_reply":"2025-10-20T04:38:05.135442Z"},"trusted":true},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":"### Processing images","metadata":{}},{"cell_type":"code","source":"class ChestXRayDataset(Dataset):\n    def __init__(self, df: pd.DataFrame, image_dir: str, img_size=IMG_SIZE, \n                             is_test=False, label_cols=None, transform=None):\n        self.df = df.reset_index(drop=True)\n        self.image_dir = image_dir\n        self.img_size = img_size\n        self.is_test = is_test\n        self.label_cols = label_cols\n        self.transform = transform\n\n        if not os.path.exists(self.image_dir):\n            raise FileNotFoundError(f\"Image directory {self.image_dir} not found.\")\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        img_name = row['Image_name']\n        img_path = os.path.join(self.image_dir, img_name)\n    \n        # load grayscale image\n        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n        if img is None or img.size == 0:\n            img = np.zeros(self.img_size, dtype=np.uint8)\n        else:\n            img = cv2.resize(img, self.img_size)\n    \n        # make (H, W, 1) for albumentations\n        img = np.expand_dims(img, axis=-1)\n    \n        # augmentation\n        if self.transform:\n            # albumentations expects dict\n            img = self.transform(image=img)[\"image\"]\n        else:\n            # fallback: to tensor\n            img = transforms.ToTensor()(img)\n    \n        if self.is_test:\n            return img\n        else:\n            labels = torch.tensor(row[self.label_cols].values.astype(np.float32))\n            return img, labels","metadata":{"execution":{"iopub.status.busy":"2025-10-20T04:38:05.136844Z","iopub.execute_input":"2025-10-20T04:38:05.137155Z","iopub.status.idle":"2025-10-20T04:38:05.148738Z","shell.execute_reply.started":"2025-10-20T04:38:05.137138Z","shell.execute_reply":"2025-10-20T04:38:05.147936Z"},"trusted":true},"outputs":[],"execution_count":24},{"cell_type":"markdown","source":"### Wrapper","metadata":{}},{"cell_type":"code","source":"class CNNWrapper(nn.Module):\n    def __init__(self, model_name, num_classes=NUM_CLASSES):\n        super().__init__()\n        self.backbone, self.feature_dim = self._get_backbone(model_name)\n        self.fc = nn.Sequential(\n            nn.Linear(self.feature_dim, 256),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(256, num_classes)\n        )\n\n    def forward(self, x):\n        features = self.backbone(x)\n        return self.fc(features)\n\n\n    def _get_backbone(self, model_name, pretrained=True):\n        if model_name == \"resnet18\":\n            model = models.resnet18(pretrained=pretrained)\n            model.conv1 = nn.Conv2d(1, 64, 7, 2, 3, bias=False)\n            feature_dim = model.fc.in_features\n            model.fc = nn.Identity()\n\n        elif model_name == \"resnext50\":\n            model = models.resnext50_32x4d(pretrained=pretrained)\n            model.conv1 = nn.Conv2d(1, 64, 7, 2, 3, bias=False)\n            feature_dim = model.fc.in_features\n            model.fc = nn.Identity()\n\n        elif model_name == \"efficientnet_b0\":\n            model = models.efficientnet_b0(pretrained=pretrained)\n            model.features[0][0] = nn.Conv2d(1, 32, 3, 2, 1, bias=False)\n            feature_dim = model.classifier[1].in_features\n            model.classifier = nn.Identity()\n\n        elif model_name == \"densenet121\":\n            model = models.densenet121(pretrained=pretrained)\n            model.features.conv0 = nn.Conv2d(1, 64, 7, 2, 3, bias=False)\n            feature_dim = model.classifier.in_features\n            model.classifier = nn.Identity()\n\n        elif model_name == \"simplecnn\":\n            model = SimpleCNN()\n            feature_dim = model.fc_out_layer.in_features\n            model.fc_out = nn.Identity()\n\n        else:\n            raise ValueError(f\"Unknown model: {model_name}\")\n\n        return model, feature_dim\n","metadata":{"execution":{"iopub.status.busy":"2025-10-20T04:38:05.150554Z","iopub.execute_input":"2025-10-20T04:38:05.150744Z","iopub.status.idle":"2025-10-20T04:38:05.166700Z","shell.execute_reply.started":"2025-10-20T04:38:05.150730Z","shell.execute_reply":"2025-10-20T04:38:05.166025Z"},"trusted":true},"outputs":[],"execution_count":25},{"cell_type":"markdown","source":"### Baseline CNN model","metadata":{}},{"cell_type":"code","source":"class SimpleCNN(nn.Module):\n    def __init__(self, num_classes=NUM_CLASSES):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 32, 3)\n        self.pool = nn.MaxPool2d(2)\n        self.conv2 = nn.Conv2d(32, 64, 3)\n        self.conv3 = nn.Conv2d(64, 128, 3)\n        self.flattened_size = 128 * 26 * 26\n        self.fc = nn.Linear(self.flattened_size, 128)\n        self.dropout = nn.Dropout(0.5)\n        self.fc_out_layer = nn.Linear(128, num_classes)\n        self.fc_out = nn.Identity()\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = self.pool(x)\n        x = F.relu(self.conv2(x))\n        x = self.pool(x)\n        x = F.relu(self.conv3(x))\n        x = self.pool(x)\n        x = x.view(x.size(0), -1)\n        x = F.relu(self.fc(x))\n        x = self.dropout(x)\n        return x  # feature vector\n","metadata":{"execution":{"iopub.status.busy":"2025-10-20T04:38:05.167275Z","iopub.execute_input":"2025-10-20T04:38:05.167511Z","iopub.status.idle":"2025-10-20T04:38:05.182258Z","shell.execute_reply.started":"2025-10-20T04:38:05.167488Z","shell.execute_reply":"2025-10-20T04:38:05.181534Z"},"trusted":true},"outputs":[],"execution_count":26},{"cell_type":"markdown","source":"### Metrics","metadata":{}},{"cell_type":"code","source":"class MetricCalculator:\n    def __init__(self, class_names=label_columns):\n        self.class_names = class_names\n    \n    def compute_auc(self, y_true, y_pred):\n        \"\"\"Вычисляет средний AUC и AUC по каждому классу.\"\"\"\n        aucs = []\n        for i in range(y_true.shape[1]):\n            try:\n                auc = roc_auc_score(y_true[:, i], y_pred[:, i])\n            except ValueError:\n                auc = np.nan  # если для класса нет положительных/отрицательных примеров\n            aucs.append(auc)\n        aucs = np.array(aucs, dtype=np.float32)\n        return np.nanmean(aucs), aucs\n    \n    def print_auc(self, auc_mean, auc_per_class, phase=\"Train\"):\n        print(f\"\\n{phase} AUC: {auc_mean:.4f}\")\n","metadata":{"execution":{"iopub.status.busy":"2025-10-20T04:38:05.183039Z","iopub.execute_input":"2025-10-20T04:38:05.183269Z","iopub.status.idle":"2025-10-20T04:38:05.196743Z","shell.execute_reply.started":"2025-10-20T04:38:05.183249Z","shell.execute_reply":"2025-10-20T04:38:05.196073Z"},"trusted":true},"outputs":[],"execution_count":27},{"cell_type":"markdown","source":"### Plots","metadata":{}},{"cell_type":"code","source":"def plot_learning_curves(model_name, history, num_epochs=NUM_EPOCHS):\n    epochs = np.arange(1, num_epochs+1)\n    os.makedirs(\"plots\", exist_ok=True)\n    \n    plt.figure(figsize=(10,4))\n    # loss\n    plt.subplot(1,2,1)\n    plt.plot(epochs, history['train']['loss'], label='train loss')\n    plt.plot(epochs, history['val']['loss'], label='val loss')\n    plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.legend()\n    plt.title(f'Loss {model_name}')\n    # auc\n    plt.subplot(1,2,2)\n    plt.plot(epochs, history['train']['auc'], label='train AUC')\n    plt.plot(epochs, history['val']['auc'], label='val AUC')\n    plt.xlabel('Epoch'); plt.ylabel('AUC'); plt.legend()\n    plt.title(f'AUC {model_name}')\n\n    plt.tight_layout()\n\n    save_path = os.path.join(\"plots\", f\"{model_name}_learning_curves_{num_epochs}_epochs.png\")\n    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n    plt.close()\n    print(f\"Saved learning curves to: {save_path}\")","metadata":{"execution":{"iopub.status.busy":"2025-10-20T04:38:05.197338Z","iopub.execute_input":"2025-10-20T04:38:05.197559Z","iopub.status.idle":"2025-10-20T04:38:05.205202Z","shell.execute_reply.started":"2025-10-20T04:38:05.197540Z","shell.execute_reply":"2025-10-20T04:38:05.204570Z"},"trusted":true},"outputs":[],"execution_count":28},{"cell_type":"code","source":"def bar_aucs(aucs_per_classes, model_name=\"model\"):\n    os.makedirs(\"plots\", exist_ok=True)\n\n    plt.figure(figsize=(30, 4))\n    plt.bar(label_columns, aucs_per_classes)\n    plt.xlabel('Class')\n    plt.ylabel('AUC')\n    plt.title(f'AUCs by Classes ({model_name})')\n\n    save_path = os.path.join(\"plots\", f\"{model_name}_aucs_per_class.png\")\n    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n    plt.close()\n    print(f\"Saved per-class AUC bar chart to: {save_path}\")","metadata":{"execution":{"iopub.status.busy":"2025-10-20T04:38:05.205897Z","iopub.execute_input":"2025-10-20T04:38:05.206095Z","iopub.status.idle":"2025-10-20T04:38:05.220869Z","shell.execute_reply.started":"2025-10-20T04:38:05.206081Z","shell.execute_reply":"2025-10-20T04:38:05.220194Z"},"trusted":true},"outputs":[],"execution_count":29},{"cell_type":"markdown","source":"### Loaders","metadata":{}},{"cell_type":"code","source":"train_dataset = ChestXRayDataset(train_data, IMAGE_DIR_TRAIN, img_size=IMG_SIZE, \n                                 is_test=False, label_cols=label_columns, transform=train_transform)\n\nval_dataset = ChestXRayDataset(val_data, IMAGE_DIR_TRAIN, img_size=IMG_SIZE, \n                               is_test=False, label_cols=label_columns, transform=val_transform)\n\n\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=3, pin_memory=True)\nval_loader   = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=3, pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2025-10-20T04:38:05.221454Z","iopub.execute_input":"2025-10-20T04:38:05.221628Z","iopub.status.idle":"2025-10-20T04:38:05.236153Z","shell.execute_reply.started":"2025-10-20T04:38:05.221614Z","shell.execute_reply":"2025-10-20T04:38:05.235434Z"},"trusted":true},"outputs":[],"execution_count":30},{"cell_type":"markdown","source":"### Save results","metadata":{}},{"cell_type":"code","source":"def save_results_csv(model_name, history, num_epochs, lr, time, filepath=\"results.csv\"):\n    row = {\n        \"Model\": model_name,\n        \"AUC\": max(history['val']['auc']),\n        \"epochs\": num_epochs,\n        \"lr\": lr,\n        \"time\": time\n    }\n\n    if os.path.exists(filepath):\n        df = pd.read_csv(filepath)\n        df = pd.concat([df, pd.DataFrame([row])], ignore_index=True)\n    else:\n        df = pd.DataFrame([row])\n\n    df.to_csv(filepath, index=False)","metadata":{"execution":{"iopub.status.busy":"2025-10-20T04:38:05.236975Z","iopub.execute_input":"2025-10-20T04:38:05.237598Z","iopub.status.idle":"2025-10-20T04:38:05.246233Z","shell.execute_reply.started":"2025-10-20T04:38:05.237581Z","shell.execute_reply":"2025-10-20T04:38:05.245559Z"},"trusted":true},"outputs":[],"execution_count":31},{"cell_type":"markdown","source":"### Train loop","metadata":{}},{"cell_type":"code","source":"def training_and_validation(model_name, model, optimizer, criterion, num_epochs=NUM_EPOCHS, lr=LR):\n    print(f'Model_name: {model_name}')\n    \n    metric_calculator = MetricCalculator()\n\n    # initialize history (только loss и AUC)\n    history = {\n        'train': {'loss': [], 'auc': []},\n        'val': {'loss': [], 'auc': []}\n    }\n\n    best_val_auc = 0.0\n    best_epoch = 0\n    best_val_auc_per_class = None\n    total_train_time = 0.0\n    \n    for epoch in range(num_epochs):\n         # ---------------------- TRAIN ----------------------\n        start_time = t.time()\n        model.train()\n        running_loss = 0.0\n        train_labels, train_preds = [], []\n\n        for batch_idx, (imgs, labels) in enumerate(train_loader):\n        \n            imgs = imgs.to(DEVICE, dtype=torch.float)\n            labels = labels.to(DEVICE, dtype=torch.float)\n        \n            optimizer.zero_grad()\n            logits = model(imgs)\n            loss = criterion(logits, labels)\n            loss.backward()\n            optimizer.step()\n        \n            running_loss += loss.item() * imgs.size(0)\n            probs = torch.sigmoid(logits).detach().cpu().numpy()\n            train_preds.append(probs)\n            train_labels.append(labels.cpu().numpy())\n\n        epoch_train_time = t.time() - start_time\n        total_train_time += epoch_train_time  \n        \n        train_preds = np.vstack(train_preds)\n        train_labels = np.vstack(train_labels)\n        train_epoch_loss = running_loss / len(train_dataset)\n        train_auc_mean, train_auc_per_class = metric_calculator.compute_auc(train_labels, train_preds)\n\n        history['train']['loss'].append(train_epoch_loss)\n        history['train']['auc'].append(train_auc_mean)\n\n        print(f\"Epoch {epoch+1} Train loss: {train_epoch_loss:.2f}\")\n        metric_calculator.print_auc(train_auc_mean, train_auc_per_class, phase=\"Train\")\n\n        # ---------------------- VALIDATION ----------------------\n        model.eval()\n        val_loss = 0.0\n        val_preds = []\n        val_labels = []\n\n        with torch.no_grad():\n            for imgs, labels in val_loader:\n                imgs = imgs.to(DEVICE, dtype=torch.float)\n                labels = labels.to(DEVICE, dtype=torch.float)\n        \n                logits = model(imgs)\n                loss = criterion(logits, labels)\n                val_loss += loss.item() * imgs.size(0)\n        \n                probs = torch.sigmoid(logits).detach().cpu().numpy()\n                val_preds.append(probs)\n                val_labels.append(labels.cpu().numpy())\n\n                del imgs, labels, logits, probs\n        \n        val_preds = np.vstack(val_preds)\n        val_labels = np.vstack(val_labels)\n        \n        val_epoch_loss = val_loss / len(val_dataset)\n        val_auc_mean, val_auc_per_class = metric_calculator.compute_auc(val_labels, val_preds)\n\n        history['val']['loss'].append(val_epoch_loss)\n        history['val']['auc'].append(val_auc_mean)\n\n        print(f\"Epoch {epoch+1} Validation loss: {val_epoch_loss:.2f}\")\n        metric_calculator.print_auc(val_auc_mean, val_auc_per_class, phase=\"Validation\")\n\n\n        # ---------------------- SAVE BEST MODEL ----------------------\n        if epoch>6 and val_auc_mean > best_val_auc:\n            best_val_auc = val_auc_mean\n            best_val_auc_per_class = val_auc_per_class.copy()  # сохраняем для bar-графика\n            best_epoch = epoch + 1\n            save_path = f\"best_{model_name}_epoch_{best_epoch}_auc{best_val_auc:.4f}.pth\"\n            torch.save(model.state_dict(), save_path)\n            print(f\"Saved new best model at epoch {best_epoch} with AUC={best_val_auc:.4f}: {save_path}\")\n\n    total_time_minutes = total_train_time/60\n    \n    print(f\"Best validation AUC={best_val_auc:.4f} at epoch {best_epoch}\")\n    print(f\"{model_name} was trained for {total_time_minutes:.0f} minutes\")\n\n\n    # ---------------------- PLOTS & SAVE HISTORY ----------------------\n    plot_learning_curves(model_name, history, num_epochs)\n    bar_aucs(best_val_auc_per_class, model_name)\n\n    save_results_csv(model_name, history, num_epochs, lr, total_time_minutes)","metadata":{"execution":{"iopub.status.busy":"2025-10-20T04:38:05.247058Z","iopub.execute_input":"2025-10-20T04:38:05.247296Z","iopub.status.idle":"2025-10-20T04:38:05.262641Z","shell.execute_reply.started":"2025-10-20T04:38:05.247277Z","shell.execute_reply":"2025-10-20T04:38:05.261960Z"},"trusted":true},"outputs":[],"execution_count":32},{"cell_type":"markdown","source":"### Launching an experiment","metadata":{}},{"cell_type":"code","source":"MODEL_NAMES = [\"simplecnn\", \"resnet18\", \"resnext50\", \"efficientnet_b0\", \"densenet121\"]","metadata":{"execution":{"iopub.status.busy":"2025-10-20T04:38:05.264467Z","iopub.execute_input":"2025-10-20T04:38:05.264729Z","iopub.status.idle":"2025-10-20T04:38:05.278028Z","shell.execute_reply.started":"2025-10-20T04:38:05.264708Z","shell.execute_reply":"2025-10-20T04:38:05.277433Z"},"trusted":true},"outputs":[],"execution_count":33},{"cell_type":"code","source":"for model_name in MODEL_NAMES:\n    model = CNNWrapper(model_name)\n    model.to(DEVICE)\n    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n    criterion = nn.BCEWithLogitsLoss()\n    training_and_validation(model_name, model, optimizer, criterion)","metadata":{"execution":{"iopub.status.busy":"2025-10-20T04:38:05.278666Z","iopub.execute_input":"2025-10-20T04:38:05.278876Z","iopub.status.idle":"2025-10-20T06:47:20.919071Z","shell.execute_reply.started":"2025-10-20T04:38:05.278861Z","shell.execute_reply":"2025-10-20T06:47:20.918273Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Model_name: simplecnn\nEpoch 1 Train loss: 0.63\n\nTrain AUC: 0.4906\nEpoch 1 Validation loss: 0.55\n\nValidation AUC: 0.4504\nEpoch 2 Train loss: 0.58\n\nTrain AUC: 0.4913\nEpoch 2 Validation loss: 0.54\n\nValidation AUC: 0.5472\nEpoch 3 Train loss: 0.56\n\nTrain AUC: 0.5131\nEpoch 3 Validation loss: 0.53\n\nValidation AUC: 0.6486\nEpoch 4 Train loss: 0.54\n\nTrain AUC: 0.5528\nEpoch 4 Validation loss: 0.51\n\nValidation AUC: 0.6977\nEpoch 5 Train loss: 0.52\n\nTrain AUC: 0.5984\nEpoch 5 Validation loss: 0.50\n\nValidation AUC: 0.7285\nEpoch 6 Train loss: 0.51\n\nTrain AUC: 0.6353\nEpoch 6 Validation loss: 0.48\n\nValidation AUC: 0.7449\nEpoch 7 Train loss: 0.49\n\nTrain AUC: 0.6647\nEpoch 7 Validation loss: 0.46\n\nValidation AUC: 0.7608\nEpoch 8 Train loss: 0.48\n\nTrain AUC: 0.6821\nEpoch 8 Validation loss: 0.45\n\nValidation AUC: 0.7684\nSaved new best model at epoch 8 with AUC=0.7684: best_simplecnn_epoch_8_auc0.7684.pth\nEpoch 9 Train loss: 0.48\n\nTrain AUC: 0.6971\nEpoch 9 Validation loss: 0.45\n\nValidation AUC: 0.7745\nSaved new best model at epoch 9 with AUC=0.7745: best_simplecnn_epoch_9_auc0.7745.pth\nEpoch 10 Train loss: 0.47\n\nTrain AUC: 0.7093\nEpoch 10 Validation loss: 0.44\n\nValidation AUC: 0.7776\nSaved new best model at epoch 10 with AUC=0.7776: best_simplecnn_epoch_10_auc0.7776.pth\nEpoch 11 Train loss: 0.46\n\nTrain AUC: 0.7170\nEpoch 11 Validation loss: 0.44\n\nValidation AUC: 0.7782\nSaved new best model at epoch 11 with AUC=0.7782: best_simplecnn_epoch_11_auc0.7782.pth\nEpoch 12 Train loss: 0.46\n\nTrain AUC: 0.7222\nEpoch 12 Validation loss: 0.44\n\nValidation AUC: 0.7808\nSaved new best model at epoch 12 with AUC=0.7808: best_simplecnn_epoch_12_auc0.7808.pth\nEpoch 13 Train loss: 0.45\n\nTrain AUC: 0.7262\nEpoch 13 Validation loss: 0.43\n\nValidation AUC: 0.7805\nEpoch 14 Train loss: 0.45\n\nTrain AUC: 0.7344\nEpoch 14 Validation loss: 0.43\n\nValidation AUC: 0.7807\nEpoch 15 Train loss: 0.45\n\nTrain AUC: 0.7331\nEpoch 15 Validation loss: 0.42\n\nValidation AUC: 0.7818\nSaved new best model at epoch 15 with AUC=0.7818: best_simplecnn_epoch_15_auc0.7818.pth\nEpoch 16 Train loss: 0.44\n\nTrain AUC: 0.7390\nEpoch 16 Validation loss: 0.42\n\nValidation AUC: 0.7807\nEpoch 17 Train loss: 0.44\n\nTrain AUC: 0.7394\nEpoch 17 Validation loss: 0.42\n\nValidation AUC: 0.7826\nSaved new best model at epoch 17 with AUC=0.7826: best_simplecnn_epoch_17_auc0.7826.pth\nEpoch 18 Train loss: 0.44\n\nTrain AUC: 0.7457\nEpoch 18 Validation loss: 0.42\n\nValidation AUC: 0.7831\nSaved new best model at epoch 18 with AUC=0.7831: best_simplecnn_epoch_18_auc0.7831.pth\nEpoch 19 Train loss: 0.44\n\nTrain AUC: 0.7406\nEpoch 19 Validation loss: 0.42\n\nValidation AUC: 0.7819\nEpoch 20 Train loss: 0.44\n\nTrain AUC: 0.7464\nEpoch 20 Validation loss: 0.42\n\nValidation AUC: 0.7809\nBest validation AUC=0.7831 at epoch 18\nsimplecnn was trained for 20 minutes\nSaved learning curves to: plots/simplecnn_learning_curves_20_epochs.png\nSaved per-class AUC bar chart to: plots/simplecnn_aucs_per_class.png\n","output_type":"stream"},{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n100%|██████████| 44.7M/44.7M [00:00<00:00, 239MB/s]\n","output_type":"stream"},{"name":"stdout","text":"Model_name: resnet18\nEpoch 1 Train loss: 0.58\n\nTrain AUC: 0.6629\nEpoch 1 Validation loss: 0.48\n\nValidation AUC: 0.7785\nEpoch 2 Train loss: 0.44\n\nTrain AUC: 0.7627\nEpoch 2 Validation loss: 0.41\n\nValidation AUC: 0.8047\nEpoch 3 Train loss: 0.40\n\nTrain AUC: 0.7928\nEpoch 3 Validation loss: 0.38\n\nValidation AUC: 0.8138\nEpoch 4 Train loss: 0.38\n\nTrain AUC: 0.8053\nEpoch 4 Validation loss: 0.37\n\nValidation AUC: 0.8228\nEpoch 5 Train loss: 0.37\n\nTrain AUC: 0.8165\nEpoch 5 Validation loss: 0.37\n\nValidation AUC: 0.8271\nEpoch 6 Train loss: 0.36\n\nTrain AUC: 0.8262\nEpoch 6 Validation loss: 0.36\n\nValidation AUC: 0.8355\nEpoch 7 Train loss: 0.36\n\nTrain AUC: 0.8332\nEpoch 7 Validation loss: 0.36\n\nValidation AUC: 0.8404\nEpoch 8 Train loss: 0.35\n\nTrain AUC: 0.8408\nEpoch 8 Validation loss: 0.36\n\nValidation AUC: 0.8438\nSaved new best model at epoch 8 with AUC=0.8438: best_resnet18_epoch_8_auc0.8438.pth\nEpoch 9 Train loss: 0.35\n\nTrain AUC: 0.8466\nEpoch 9 Validation loss: 0.36\n\nValidation AUC: 0.8450\nSaved new best model at epoch 9 with AUC=0.8450: best_resnet18_epoch_9_auc0.8450.pth\nEpoch 10 Train loss: 0.34\n\nTrain AUC: 0.8540\nEpoch 10 Validation loss: 0.36\n\nValidation AUC: 0.8476\nSaved new best model at epoch 10 with AUC=0.8476: best_resnet18_epoch_10_auc0.8476.pth\nEpoch 11 Train loss: 0.33\n\nTrain AUC: 0.8600\nEpoch 11 Validation loss: 0.36\n\nValidation AUC: 0.8469\nEpoch 12 Train loss: 0.33\n\nTrain AUC: 0.8640\nEpoch 12 Validation loss: 0.36\n\nValidation AUC: 0.8488\nSaved new best model at epoch 12 with AUC=0.8488: best_resnet18_epoch_12_auc0.8488.pth\nEpoch 13 Train loss: 0.32\n\nTrain AUC: 0.8695\nEpoch 13 Validation loss: 0.36\n\nValidation AUC: 0.8484\nEpoch 14 Train loss: 0.32\n\nTrain AUC: 0.8748\nEpoch 14 Validation loss: 0.36\n\nValidation AUC: 0.8497\nSaved new best model at epoch 14 with AUC=0.8497: best_resnet18_epoch_14_auc0.8497.pth\nEpoch 15 Train loss: 0.31\n\nTrain AUC: 0.8783\nEpoch 15 Validation loss: 0.36\n\nValidation AUC: 0.8504\nSaved new best model at epoch 15 with AUC=0.8504: best_resnet18_epoch_15_auc0.8504.pth\nEpoch 16 Train loss: 0.31\n\nTrain AUC: 0.8831\nEpoch 16 Validation loss: 0.35\n\nValidation AUC: 0.8516\nSaved new best model at epoch 16 with AUC=0.8516: best_resnet18_epoch_16_auc0.8516.pth\nEpoch 17 Train loss: 0.30\n\nTrain AUC: 0.8840\nEpoch 17 Validation loss: 0.35\n\nValidation AUC: 0.8518\nSaved new best model at epoch 17 with AUC=0.8518: best_resnet18_epoch_17_auc0.8518.pth\nEpoch 18 Train loss: 0.30\n\nTrain AUC: 0.8912\nEpoch 18 Validation loss: 0.36\n\nValidation AUC: 0.8479\nEpoch 19 Train loss: 0.30\n\nTrain AUC: 0.8935\nEpoch 19 Validation loss: 0.36\n\nValidation AUC: 0.8476\nEpoch 20 Train loss: 0.29\n\nTrain AUC: 0.8974\nEpoch 20 Validation loss: 0.36\n\nValidation AUC: 0.8475\nBest validation AUC=0.8518 at epoch 17\nresnet18 was trained for 20 minutes\nSaved learning curves to: plots/resnet18_learning_curves_20_epochs.png\nSaved per-class AUC bar chart to: plots/resnet18_aucs_per_class.png\n","output_type":"stream"},{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth\" to /root/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth\n100%|██████████| 95.8M/95.8M [00:00<00:00, 210MB/s]\n","output_type":"stream"},{"name":"stdout","text":"Model_name: resnext50\nEpoch 1 Train loss: 0.52\n\nTrain AUC: 0.7028\nEpoch 1 Validation loss: 0.41\n\nValidation AUC: 0.7932\nEpoch 2 Train loss: 0.40\n\nTrain AUC: 0.7818\nEpoch 2 Validation loss: 0.38\n\nValidation AUC: 0.8134\nEpoch 3 Train loss: 0.37\n\nTrain AUC: 0.8084\nEpoch 3 Validation loss: 0.37\n\nValidation AUC: 0.8212\nEpoch 4 Train loss: 0.36\n\nTrain AUC: 0.8222\nEpoch 4 Validation loss: 0.37\n\nValidation AUC: 0.8282\nEpoch 5 Train loss: 0.35\n\nTrain AUC: 0.8295\nEpoch 5 Validation loss: 0.36\n\nValidation AUC: 0.8337\nEpoch 6 Train loss: 0.34\n\nTrain AUC: 0.8424\nEpoch 6 Validation loss: 0.36\n\nValidation AUC: 0.8349\nEpoch 7 Train loss: 0.33\n\nTrain AUC: 0.8510\nEpoch 7 Validation loss: 0.36\n\nValidation AUC: 0.8388\nEpoch 8 Train loss: 0.32\n\nTrain AUC: 0.8603\nEpoch 8 Validation loss: 0.36\n\nValidation AUC: 0.8400\nSaved new best model at epoch 8 with AUC=0.8400: best_resnext50_epoch_8_auc0.8400.pth\nEpoch 9 Train loss: 0.31\n\nTrain AUC: 0.8718\nEpoch 9 Validation loss: 0.36\n\nValidation AUC: 0.8429\nSaved new best model at epoch 9 with AUC=0.8429: best_resnext50_epoch_9_auc0.8429.pth\nEpoch 10 Train loss: 0.31\n\nTrain AUC: 0.8754\nEpoch 10 Validation loss: 0.36\n\nValidation AUC: 0.8442\nSaved new best model at epoch 10 with AUC=0.8442: best_resnext50_epoch_10_auc0.8442.pth\nEpoch 11 Train loss: 0.30\n\nTrain AUC: 0.8815\nEpoch 11 Validation loss: 0.36\n\nValidation AUC: 0.8461\nSaved new best model at epoch 11 with AUC=0.8461: best_resnext50_epoch_11_auc0.8461.pth\nEpoch 12 Train loss: 0.29\n\nTrain AUC: 0.8895\nEpoch 12 Validation loss: 0.37\n\nValidation AUC: 0.8451\nEpoch 13 Train loss: 0.28\n\nTrain AUC: 0.8961\nEpoch 13 Validation loss: 0.37\n\nValidation AUC: 0.8426\nEpoch 14 Train loss: 0.28\n\nTrain AUC: 0.9038\nEpoch 14 Validation loss: 0.37\n\nValidation AUC: 0.8448\nEpoch 15 Train loss: 0.27\n\nTrain AUC: 0.9060\nEpoch 15 Validation loss: 0.37\n\nValidation AUC: 0.8464\nSaved new best model at epoch 15 with AUC=0.8464: best_resnext50_epoch_15_auc0.8464.pth\nEpoch 16 Train loss: 0.26\n\nTrain AUC: 0.9114\nEpoch 16 Validation loss: 0.37\n\nValidation AUC: 0.8491\nSaved new best model at epoch 16 with AUC=0.8491: best_resnext50_epoch_16_auc0.8491.pth\nEpoch 17 Train loss: 0.26\n\nTrain AUC: 0.9138\nEpoch 17 Validation loss: 0.37\n\nValidation AUC: 0.8483\nEpoch 18 Train loss: 0.25\n\nTrain AUC: 0.9216\nEpoch 18 Validation loss: 0.37\n\nValidation AUC: 0.8477\nEpoch 19 Train loss: 0.25\n\nTrain AUC: 0.9273\nEpoch 19 Validation loss: 0.37\n\nValidation AUC: 0.8469\nEpoch 20 Train loss: 0.24\n\nTrain AUC: 0.9276\nEpoch 20 Validation loss: 0.38\n\nValidation AUC: 0.8470\nBest validation AUC=0.8491 at epoch 16\nresnext50 was trained for 22 minutes\nSaved learning curves to: plots/resnext50_learning_curves_20_epochs.png\n","output_type":"stream"},{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n","output_type":"stream"},{"name":"stdout","text":"Saved per-class AUC bar chart to: plots/resnext50_aucs_per_class.png\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 20.5M/20.5M [00:00<00:00, 188MB/s]\n","output_type":"stream"},{"name":"stdout","text":"Model_name: efficientnet_b0\nEpoch 1 Train loss: 0.64\n\nTrain AUC: 0.6160\nEpoch 1 Validation loss: 0.58\n\nValidation AUC: 0.7423\nEpoch 2 Train loss: 0.52\n\nTrain AUC: 0.7371\nEpoch 2 Validation loss: 0.49\n\nValidation AUC: 0.7584\nEpoch 3 Train loss: 0.47\n\nTrain AUC: 0.7567\nEpoch 3 Validation loss: 0.46\n\nValidation AUC: 0.7728\nEpoch 4 Train loss: 0.45\n\nTrain AUC: 0.7684\nEpoch 4 Validation loss: 0.44\n\nValidation AUC: 0.7842\nEpoch 5 Train loss: 0.43\n\nTrain AUC: 0.7843\nEpoch 5 Validation loss: 0.42\n\nValidation AUC: 0.7925\nEpoch 6 Train loss: 0.41\n\nTrain AUC: 0.7906\nEpoch 6 Validation loss: 0.39\n\nValidation AUC: 0.8055\nEpoch 7 Train loss: 0.39\n\nTrain AUC: 0.8012\nEpoch 7 Validation loss: 0.38\n\nValidation AUC: 0.8095\nEpoch 8 Train loss: 0.38\n\nTrain AUC: 0.8070\nEpoch 8 Validation loss: 0.38\n\nValidation AUC: 0.8150\nSaved new best model at epoch 8 with AUC=0.8150: best_efficientnet_b0_epoch_8_auc0.8150.pth\nEpoch 9 Train loss: 0.38\n\nTrain AUC: 0.8146\nEpoch 9 Validation loss: 0.38\n\nValidation AUC: 0.8176\nSaved new best model at epoch 9 with AUC=0.8176: best_efficientnet_b0_epoch_9_auc0.8176.pth\nEpoch 10 Train loss: 0.37\n\nTrain AUC: 0.8209\nEpoch 10 Validation loss: 0.37\n\nValidation AUC: 0.8209\nSaved new best model at epoch 10 with AUC=0.8209: best_efficientnet_b0_epoch_10_auc0.8209.pth\nEpoch 11 Train loss: 0.37\n\nTrain AUC: 0.8222\nEpoch 11 Validation loss: 0.37\n\nValidation AUC: 0.8238\nSaved new best model at epoch 11 with AUC=0.8238: best_efficientnet_b0_epoch_11_auc0.8238.pth\nEpoch 12 Train loss: 0.36\n\nTrain AUC: 0.8295\nEpoch 12 Validation loss: 0.37\n\nValidation AUC: 0.8267\nSaved new best model at epoch 12 with AUC=0.8267: best_efficientnet_b0_epoch_12_auc0.8267.pth\nEpoch 13 Train loss: 0.36\n\nTrain AUC: 0.8287\nEpoch 13 Validation loss: 0.37\n\nValidation AUC: 0.8297\nSaved new best model at epoch 13 with AUC=0.8297: best_efficientnet_b0_epoch_13_auc0.8297.pth\nEpoch 14 Train loss: 0.36\n\nTrain AUC: 0.8318\nEpoch 14 Validation loss: 0.37\n\nValidation AUC: 0.8328\nSaved new best model at epoch 14 with AUC=0.8328: best_efficientnet_b0_epoch_14_auc0.8328.pth\nEpoch 15 Train loss: 0.36\n\nTrain AUC: 0.8361\nEpoch 15 Validation loss: 0.36\n\nValidation AUC: 0.8336\nSaved new best model at epoch 15 with AUC=0.8336: best_efficientnet_b0_epoch_15_auc0.8336.pth\nEpoch 16 Train loss: 0.35\n\nTrain AUC: 0.8388\nEpoch 16 Validation loss: 0.37\n\nValidation AUC: 0.8348\nSaved new best model at epoch 16 with AUC=0.8348: best_efficientnet_b0_epoch_16_auc0.8348.pth\nEpoch 17 Train loss: 0.35\n\nTrain AUC: 0.8410\nEpoch 17 Validation loss: 0.36\n\nValidation AUC: 0.8371\nSaved new best model at epoch 17 with AUC=0.8371: best_efficientnet_b0_epoch_17_auc0.8371.pth\nEpoch 18 Train loss: 0.35\n\nTrain AUC: 0.8426\nEpoch 18 Validation loss: 0.36\n\nValidation AUC: 0.8385\nSaved new best model at epoch 18 with AUC=0.8385: best_efficientnet_b0_epoch_18_auc0.8385.pth\nEpoch 19 Train loss: 0.35\n\nTrain AUC: 0.8439\nEpoch 19 Validation loss: 0.36\n\nValidation AUC: 0.8406\nSaved new best model at epoch 19 with AUC=0.8406: best_efficientnet_b0_epoch_19_auc0.8406.pth\nEpoch 20 Train loss: 0.35\n\nTrain AUC: 0.8458\nEpoch 20 Validation loss: 0.36\n\nValidation AUC: 0.8415\nSaved new best model at epoch 20 with AUC=0.8415: best_efficientnet_b0_epoch_20_auc0.8415.pth\nBest validation AUC=0.8415 at epoch 20\nefficientnet_b0 was trained for 21 minutes\nSaved learning curves to: plots/efficientnet_b0_learning_curves_20_epochs.png\nSaved per-class AUC bar chart to: plots/efficientnet_b0_aucs_per_class.png\n","output_type":"stream"},{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n100%|██████████| 30.8M/30.8M [00:00<00:00, 230MB/s]\n","output_type":"stream"},{"name":"stdout","text":"Model_name: densenet121\nEpoch 1 Train loss: 0.62\n\nTrain AUC: 0.5954\nEpoch 1 Validation loss: 0.53\n\nValidation AUC: 0.7538\nEpoch 2 Train loss: 0.48\n\nTrain AUC: 0.7434\nEpoch 2 Validation loss: 0.44\n\nValidation AUC: 0.7911\nEpoch 3 Train loss: 0.42\n\nTrain AUC: 0.7789\nEpoch 3 Validation loss: 0.40\n\nValidation AUC: 0.8117\nEpoch 4 Train loss: 0.39\n\nTrain AUC: 0.7932\nEpoch 4 Validation loss: 0.38\n\nValidation AUC: 0.8212\nEpoch 5 Train loss: 0.38\n\nTrain AUC: 0.8089\nEpoch 5 Validation loss: 0.37\n\nValidation AUC: 0.8270\nEpoch 6 Train loss: 0.37\n\nTrain AUC: 0.8154\nEpoch 6 Validation loss: 0.37\n\nValidation AUC: 0.8317\nEpoch 7 Train loss: 0.36\n\nTrain AUC: 0.8252\nEpoch 7 Validation loss: 0.37\n\nValidation AUC: 0.8344\nEpoch 8 Train loss: 0.36\n\nTrain AUC: 0.8339\nEpoch 8 Validation loss: 0.36\n\nValidation AUC: 0.8356\nSaved new best model at epoch 8 with AUC=0.8356: best_densenet121_epoch_8_auc0.8356.pth\nEpoch 9 Train loss: 0.35\n\nTrain AUC: 0.8407\nEpoch 9 Validation loss: 0.36\n\nValidation AUC: 0.8382\nSaved new best model at epoch 9 with AUC=0.8382: best_densenet121_epoch_9_auc0.8382.pth\nEpoch 10 Train loss: 0.35\n\nTrain AUC: 0.8436\nEpoch 10 Validation loss: 0.36\n\nValidation AUC: 0.8409\nSaved new best model at epoch 10 with AUC=0.8409: best_densenet121_epoch_10_auc0.8409.pth\nEpoch 11 Train loss: 0.34\n\nTrain AUC: 0.8451\nEpoch 11 Validation loss: 0.36\n\nValidation AUC: 0.8401\nEpoch 12 Train loss: 0.34\n\nTrain AUC: 0.8505\nEpoch 12 Validation loss: 0.36\n\nValidation AUC: 0.8420\nSaved new best model at epoch 12 with AUC=0.8420: best_densenet121_epoch_12_auc0.8420.pth\nEpoch 13 Train loss: 0.33\n\nTrain AUC: 0.8567\nEpoch 13 Validation loss: 0.36\n\nValidation AUC: 0.8424\nSaved new best model at epoch 13 with AUC=0.8424: best_densenet121_epoch_13_auc0.8424.pth\nEpoch 14 Train loss: 0.33\n\nTrain AUC: 0.8615\nEpoch 14 Validation loss: 0.36\n\nValidation AUC: 0.8442\nSaved new best model at epoch 14 with AUC=0.8442: best_densenet121_epoch_14_auc0.8442.pth\nEpoch 15 Train loss: 0.33\n\nTrain AUC: 0.8646\nEpoch 15 Validation loss: 0.36\n\nValidation AUC: 0.8458\nSaved new best model at epoch 15 with AUC=0.8458: best_densenet121_epoch_15_auc0.8458.pth\nEpoch 16 Train loss: 0.32\n\nTrain AUC: 0.8696\nEpoch 16 Validation loss: 0.36\n\nValidation AUC: 0.8457\nEpoch 17 Train loss: 0.32\n\nTrain AUC: 0.8736\nEpoch 17 Validation loss: 0.36\n\nValidation AUC: 0.8440\nEpoch 18 Train loss: 0.31\n\nTrain AUC: 0.8760\nEpoch 18 Validation loss: 0.36\n\nValidation AUC: 0.8441\nEpoch 19 Train loss: 0.31\n\nTrain AUC: 0.8794\nEpoch 19 Validation loss: 0.36\n\nValidation AUC: 0.8434\nEpoch 20 Train loss: 0.30\n\nTrain AUC: 0.8836\nEpoch 20 Validation loss: 0.36\n\nValidation AUC: 0.8463\nSaved new best model at epoch 20 with AUC=0.8463: best_densenet121_epoch_20_auc0.8463.pth\nBest validation AUC=0.8463 at epoch 20\ndensenet121 was trained for 21 minutes\nSaved learning curves to: plots/densenet121_learning_curves_20_epochs.png\nSaved per-class AUC bar chart to: plots/densenet121_aucs_per_class.png\n","output_type":"stream"}],"execution_count":34}]}